{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://ai.plainenglish.io/vggnet-with-tensorflow-transfer-learning-with-vgg16-included-7e5f6fa9479a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import datasets, layers, models, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test)=tf.keras.datasets.mnist.load_data()\n",
    "x_train = tf.pad(x_train, [[0, 0], [2,2], [2,2]])/255\n",
    "x_test = tf.pad(x_test, [[0, 0], [2,2], [2,2]])/255\n",
    "x_train = tf.expand_dims(x_train, axis=3, name=None)\n",
    "x_test = tf.expand_dims(x_test, axis=3, name=None)\n",
    "x_train = tf.repeat(x_train, 3, axis=3)\n",
    "x_test = tf.repeat(x_test, 3, axis=3)\n",
    "x_val = x_train[-2000:,:,:]\n",
    "y_val = y_train[-2000:]\n",
    "x_train = x_train[:-2000,:,:]\n",
    "y_train = y_train[:-2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "23068672/58889256 [==========>...................] - ETA: 2:46"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Incomplete or corrupted file detected. The auto file hash does not match the provided value of 6d6bbae143d832006294945121d1f1fc.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m base_model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mapplications\u001b[39m.\u001b[39;49mVGG16(weights \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mimagenet\u001b[39;49m\u001b[39m'\u001b[39;49m, include_top \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m, input_shape \u001b[39m=\u001b[39;49m (\u001b[39m32\u001b[39;49m,\u001b[39m32\u001b[39;49m,\u001b[39m3\u001b[39;49m))\n\u001b[0;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m base_model\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m      3\u001b[0m   layer\u001b[39m.\u001b[39mtrainable \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\applications\\vgg16.py:242\u001b[0m, in \u001b[0;36mVGG16\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[0;32m    235\u001b[0m         weights_path \u001b[39m=\u001b[39m data_utils\u001b[39m.\u001b[39mget_file(\n\u001b[0;32m    236\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mvgg16_weights_tf_dim_ordering_tf_kernels.h5\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    237\u001b[0m             WEIGHTS_PATH,\n\u001b[0;32m    238\u001b[0m             cache_subdir\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmodels\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    239\u001b[0m             file_hash\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m64373286793e3c8b2b4e3219cbf3544b\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    240\u001b[0m         )\n\u001b[0;32m    241\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 242\u001b[0m         weights_path \u001b[39m=\u001b[39m data_utils\u001b[39m.\u001b[39;49mget_file(\n\u001b[0;32m    243\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mvgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    244\u001b[0m             WEIGHTS_PATH_NO_TOP,\n\u001b[0;32m    245\u001b[0m             cache_subdir\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmodels\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    246\u001b[0m             file_hash\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m6d6bbae143d832006294945121d1f1fc\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    247\u001b[0m         )\n\u001b[0;32m    248\u001b[0m     model\u001b[39m.\u001b[39mload_weights(weights_path)\n\u001b[0;32m    249\u001b[0m \u001b[39melif\u001b[39;00m weights \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\data_utils.py:362\u001b[0m, in \u001b[0;36mget_file\u001b[1;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[0;32m    360\u001b[0m     \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(fpath) \u001b[39mand\u001b[39;00m file_hash \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    361\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m validate_file(fpath, file_hash, algorithm\u001b[39m=\u001b[39mhash_algorithm):\n\u001b[1;32m--> 362\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    363\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mIncomplete or corrupted file detected. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m{\u001b[39;00mhash_algorithm\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mfile hash does not match the provided value \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mof \u001b[39m\u001b[39m{\u001b[39;00mfile_hash\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    367\u001b[0m             )\n\u001b[0;32m    369\u001b[0m \u001b[39mif\u001b[39;00m untar:\n\u001b[0;32m    370\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(untar_fpath):\n",
      "\u001b[1;31mValueError\u001b[0m: Incomplete or corrupted file detected. The auto file hash does not match the provided value of 6d6bbae143d832006294945121d1f1fc."
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.VGG16(weights = 'imagenet', include_top = False, input_shape = (32,32,3))\n",
    "for layer in base_model.layers:\n",
    "  layer.trainable = False\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Flatten()(base_model.output)\n",
    "x = layers.Dense(4096, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(4096, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "predictions = layers.Dense(10, activation = 'softmax')(x)\n",
    "head_model = Model(inputs = base_model.input, outputs = predictions)\n",
    "head_model.compile(optimizer='adam', loss=losses.sparse_categorical_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = head_model.fit(x_train, y_train, batch_size=64, epochs=40, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(15,15))\n",
    "axs[0].plot(history.history['loss'])\n",
    "axs[0].plot(history.history['val_loss'])\n",
    "axs[0].title.set_text('Training Loss vs Validation Loss')\n",
    "axs[0].set_xlabel('Epochs')\n",
    "axs[0].set_ylabel('Loss')\n",
    "axs[0].legend(['Train','Val'])\n",
    "axs[1].plot(history.history['accuracy'])\n",
    "axs[1].plot(history.history['val_accuracy'])\n",
    "axs[1].title.set_text('Training Accuracy vs Validation Accuracy')\n",
    "axs[1].set_xlabel('Epochs')\n",
    "axs[1].set_ylabel('Accuracy')\n",
    "axs[1].legend(['Train', 'Val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_model.evaluate(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
