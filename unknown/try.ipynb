{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 2341, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 2327, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 2315, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 2283, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\input_spec.py\", line 219, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Layer \"sequential_26\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(32, 100) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(32, 1) dtype=int32>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\GitHub\\FYP trial\\skin lesion classification\\try.ipynb Cell 1\u001b[0m line \u001b[0;36m8\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GitHub/FYP%20trial/skin%20lesion%20classification/try.ipynb#W0sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m noise \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mnormal(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, size\u001b[39m=\u001b[39m(batch_size, z_dim))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GitHub/FYP%20trial/skin%20lesion%20classification/try.ipynb#W0sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m sampled_labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m, num_classes, batch_size)\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/GitHub/FYP%20trial/skin%20lesion%20classification/try.ipynb#W0sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m generated_images \u001b[39m=\u001b[39m generator\u001b[39m.\u001b[39;49mpredict([noise, sampled_labels])\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GitHub/FYP%20trial/skin%20lesion%20classification/try.ipynb#W0sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m batch_idx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m, df\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], batch_size)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GitHub/FYP%20trial/skin%20lesion%20classification/try.ipynb#W0sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m real_images \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filer0yyibh2.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 2341, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 2327, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 2315, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 2283, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\input_spec.py\", line 219, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Layer \"sequential_26\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(32, 100) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(32, 1) dtype=int32>]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow.keras.layers import Dense, LeakyReLU, BatchNormalization, Reshape, Flatten, Input, Embedding, Concatenate, Multiply\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the Generator\n",
    "def build_generator(z_dim, img_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=z_dim))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dense(256))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dense(np.prod(img_shape), activation='tanh'))\n",
    "    model.add(Reshape(img_shape))\n",
    "    return model\n",
    "\n",
    "# Define the Discriminator\n",
    "def build_discriminator(img_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=img_shape))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(Dense(256))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "# Define the GAN\n",
    "def build_gan(generator, discriminator):\n",
    "    z = Input(shape=(z_dim,))\n",
    "    label = Input(shape=(1,), dtype='int32')\n",
    "    label_embedding = Embedding(num_classes, z_dim)(label)\n",
    "    label_embedding = Flatten()(label_embedding)\n",
    "    joined_representation = Multiply()([z, label_embedding])\n",
    "    img = generator(joined_representation)\n",
    "    validity = discriminator([img, label])\n",
    "    return Model([z, label], validity)\n",
    "\n",
    "# Set parameters\n",
    "z_dim = 100\n",
    "img_shape = (224, 224, 1)  # Assuming images are grayscale with dimensions 224x224\n",
    "num_classes = 7  # Assuming you have 7 classes in your dataset\n",
    "data_folder = 'dataset/HAM10000_new_folder/'\n",
    "csv_file = 'dataset/HAM10000_metadata.csv'\n",
    "batch_size = 32\n",
    "epochs = 10000\n",
    "batch_count = 32\n",
    "save_interval = 1000\n",
    "\n",
    "# Build and compile the models\n",
    "generator = build_generator(z_dim, img_shape, num_classes)\n",
    "discriminator = build_discriminator(img_shape, num_classes)\n",
    "\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(0.0002, 0.5), metrics=['accuracy'])\n",
    "\n",
    "discriminator.trainable = False\n",
    "gan = build_gan(generator, discriminator)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(0.0002, 0.5))\n",
    "\n",
    "# Read the CSV file and convert labels to integers\n",
    "df = pd.read_csv(csv_file)\n",
    "label_dict = {label: idx for idx, label in enumerate(df['dx'].unique())}\n",
    "df['label'] = df['dx'].map(label_dict)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    for _ in range(batch_count):\n",
    "        noise = np.random.normal(0, 1, size=(batch_size, z_dim))\n",
    "        sampled_labels = np.random.randint(0, num_classes, batch_size).reshape(-1, 1)\n",
    "\n",
    "        generated_images = generator.predict([noise, sampled_labels])\n",
    "\n",
    "        batch_idx = np.random.randint(0, df.shape[0], batch_size)\n",
    "        real_images = []\n",
    "\n",
    "        for idx in batch_idx:\n",
    "            image_id = df.iloc[idx]['image_id']\n",
    "            img_path = os.path.join(data_folder, f'{image_id}.jpg')\n",
    "            img = load_img(img_path, color_mode='grayscale', target_size=(img_shape[0], img_shape[1]))\n",
    "            img_array = img_to_array(img)\n",
    "            img_array = img_array / 255.0\n",
    "            real_images.append(img_array)\n",
    "\n",
    "        real_images = np.array(real_images)\n",
    "        labels = df.iloc[batch_idx]['label'].values.reshape(-1, 1)\n",
    "\n",
    "        X = np.concatenate([real_images, generated_images])\n",
    "        y_labels = np.concatenate([np.ones((batch_size, 1)), np.zeros((batch_size, 1))])\n",
    "        y_labels = np.concatenate([y_labels, y_labels])\n",
    "\n",
    "        d_loss = discriminator.train_on_batch([X, np.concatenate([labels, sampled_labels])], y_labels)\n",
    "\n",
    "        noise = np.random.normal(0, 1, size=(batch_size, z_dim))\n",
    "        sampled_labels = np.random.randint(0, num_classes, batch_size).reshape(-1, 1)\n",
    "\n",
    "        g_loss = gan.train_on_batch([noise, sampled_labels], np.ones((batch_size, 1)))\n",
    "\n",
    "    print(f\"Epoch {epoch}, D Loss: {d_loss[0]}, G Loss: {g_loss}\")\n",
    "\n",
    "    if epoch % save_interval == 0:\n",
    "        # Save generated images here (if desired)\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
